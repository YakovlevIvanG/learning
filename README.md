# Учебные проекты

В данном репозитории представлены только учебные проекты, выполненные мной в процессе обучения.

## Содержание
<details>
<summary>Показать/скрыть содержание</summary>
- [Проект "Снижение энергопотребления на металлургическом комбинате"](#проект-снижение-энергопотребления-на-металлургическом-комбинате)
- [Проект "Фотохостинг: подбор фотографий по описанию"](#проект-фотохостинг-подбор-фотографий-по-описанию)
- [Проект "Классификация твитов по токсичности"](#проект-классификация-твиты-по-токсичности)
- [Проект "Прогнозирование загруженности такси"](#проект-прогнозирование-загруженности-такси)
- [Проект "Прогнозирование вероятности ДТП в каршеринге"](#проект-прогнозирование-вероятности-дтп-в-каршеринге)
- [Проект "Прогнозирование температуры звезды"](#проект-прогнозирование-температуры-звезды)
- [Проект "Определение стоимости автомобилей"](#проект-определение-стоимости-автомобилей)
- [Проект "Предсказание стоимости жилья"](#проект-предсказание-стоимости-жилья)
- [Проект "Выбор локации для скважины"](#проект-выбор-локации-для-скважины)
- [Проект "Оценка уровня удовлетворенности сотрудников"](#проект-оценка-уровня-удовлетворенности-сотрудников)
- [Проект "Персонализация предложений для пользователей"](#проект-персонализация-предложений-для-пользователей)
- [Проект "Отбор буренок для покупки"](#проект-отбор-буренок-для-покупки)
- [Проект "Анализ сервиса проката самокатов"](#проект-анализ-сервиса-проката-самокатов)
- [Проект "Исследование данных о российском кинопрокате"](#проект-исследование-данных-о-российском-кинопрокате)
- [Проект "Исследование объявлений о продаже квартир"](#проект-исследование-объявлений-о-продаже-квартир)
- [Проект "Исследование надежности заемщиков"](#проект-исследование-надежности-заемщиков)
- [Проект "Прогнозирование успешности стартапа"](#проект-прогнозирование-успешности-стартапа)
- [Проект "Категоризация клиентов маркетплейса"](#проект-категоризация-клиентов-маркетплейса)
</details>

## Проект "Снижение энергопотребления на металлургическом комбинате"
Цель проекта:  
Разработать модель, способную предсказывать конечную температуру плавки.

Задачи проекта:
1. Проанализировать предоставленные данные.
2. Подготовить данные, обработав аномальные значения и подготовив новые признаки.
3. Составить модели для обучения, среди которых дерево решений, градиентный бустинг и нейросети.
4. Интерпретировать работу модели, выявив наиболее значимые признаки.

План проекта:
1. Загрузить данные из базы данных.
2. Сделать анализ данных.
3. Обработать аномальные значения.
4. Добавить новые признаки.
5. Составить и обучить модели.
6. Проанализировать модели.
7. Сделать выводы по итогам работы.

Описание работы  

Чтобы оптимизировать производственные расходы, металлургический комбинат «Стальная птица» решил уменьшить потребление электроэнергии на этапе обработки стали. Для этого комбинату нужно контролировать температуру сплава. Разработанная модель необходима для имитации технологического процесса.  

Процесс обработки  

Сталь обрабатывают в металлическом ковше вместимостью около 100 тонн. Чтобы ковш выдерживал высокие температуры, изнутри его облицовывают огнеупорным кирпичом. Расплавленную сталь заливают в ковш и подогревают до нужной температуры графитовыми электродами. Они установлены на крышке ковша.
Сначала происходит десульфурация — из стали выводят серу и корректируют её химический состав добавлением примесей. Затем сталь легируют — добавляют в неё куски сплава из бункера для сыпучих материалов или порошковую проволоку через специальный трайб-аппарат.  

Прежде чем в первый раз ввести легирующие добавки, персонал предприятия производит химический анализ стали и измеряет её температуру. Потом температуру на несколько минут повышают, уже после этого добавляют легирующие материалы и продувают сталь инертным газом, чтобы перемешать, а затем снова проводят измерения. Такой цикл повторяется до тех пор, пока не будут достигнуты нужный химический состав стали и оптимальная температура плавки.  

Дальше расплавленная сталь отправляется на доводку металла или поступает в машину непрерывной разливки. Оттуда готовый продукт выходит в виде заготовок-слябов (англ. slab, «плита»).  

Данные хранятся в Sqlite  — СУБД, в которой база данных представлена одним файлом.

**Выводы**
В рамках работы выполнено:  
1. Загружены данные из базы данных.
2. Сделан анализ данных.
3. Обработаны аномальные значения.
4. Добавлены новые признаки.
5. Составлены и обучены несколько моделей, включая нейросеть.
6. Проанализирована работа лучшей модели.

Результаты работы  
1. Наилучше моделью после перебора является CatBoost с метрикой MAE 5.65. Нейросеть показала результат хуже, около 7,9.
2. Наиболее важный признак для модели - стартовая температура.
3. Также для модели важными оказались продолжительность нагрева, интервал между нагревами, затраченная энергия. Данные признаки вполне объяснимы с точки зрения физики процесса.

Предложения по улучшению прогноза
1. Предоставить характеристики сыпучего материала, а именно энтальпии плавления, теплоемкости и теплопроводности.
2. Предоставить площадь "зеркала" ковша.
3. Предоставить количество нагревателей в ковше и их относительное месторасположение.
Данные параметры позволят уточнить расчет с применением физико-химических расчетов.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/metallurgical_plant.ipynb)


## Проект "Фотохостинг: подбор фотографий по описанию"
**Описание проекта**
Цель работы  
Разработать модель, способную по описанию выполнить подобрать изображение.

Задачи, решаемые в работе  
1. Анализ предоставленного датасета для обучения и удаление фотографий, нарушающих законодательство.
2. Векторизация фотографий.
3. Векторизация текста.
4. Формирование и обучение модели.
5. Оценка качество модели.

План работы:  
1. Загрузить информацию о датасете.
2. Обработать оценки экспертов и крауда для определения совпадения фотографии и описания.
3. Удалить из обучающей выборке изображения, нарушающие законодательство.
4. Векторизовать изображения.
5. Векторизовать описания.
6. Сформировать несколько моделей и обучить их.
7. Оценить качество каждой модели и выбрать лучшую.
8. С помощью модели подобрать наиболее подходящее изображение по описанию.
9. Оценить визуально качество работы модели.


Описание работы

Модель необходима для фотохостинга для профессиональных фотографов «Со Смыслом» (“With Sense”).  

Пользователи размещают свои фотографии на хостинге и сопровождают их полным описанием: указывают место съёмок, модель камеры и т. д. Отличительная особенность сервиса — описание: его может предоставить не только тот, кто размещает фотографию, но и другие пользователи портала.  

В настоящий момент реализуется эксперимент по разработке поиска референсных фотографий для фотографов. Суть поиска заключается в следующем: пользователь сервиса вводит описание нужной сцены. Сервис выводит несколько фотографий с такой же или похожей сценой.  

Эксперимент необходимо защитить перед руководителем компании. Для защиты необходимо презентовать PoC (Proof of Concept, Проверка концепции). Для демонстрационной версии нужно выбрать лучшую  модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — и покажет, насколько текст и картинка подходят друг другу.
На основе лучшей модели можно будет собрать предварительную версию продукта.


Юридические ограничения  

В некоторых странах действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно, текстов, изображений, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16-ти лет. В связи с этим при подобных запросах должен показываться дисклеймер "This image is unavailable in your country in compliance with local laws".


**Выводы по работе:**
В рамках работы сделано:  
1. Выведена общая оценка соответствия картинок и описания.
2. Удалены из обучающей выборки картинки, содержащие изображения детей.
3. Векторизованы изображения и текст.
4. Сформированы и обучены несколько моделей.

Результаты работы:
1. Лучшей моделью при обучении стала нейронная сеть. Её метрика MAE составила около 0,22.
2. При использовании на тестовой выборке из 10 описаний часть изображений выводится ошибочно, но в ряде аспектов изображения и описания совпадают.
3. При запросе, который содержит упоминание детей, модель вместо фотографии выводит дисклеймер.

Рекомендации:  
Продолжить обучение модели для улучшения качества работы. Для этого может быть полезно применить аугментацию входящих данных, точнее настроить параметры модели.


[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/selection_of_photos_by_description.ipynb)



## Проект "Классификация твиты по токсичности"
**Описание проекта**
Цель работы: разработать модель, способную классифицировать твиты на токсичные и нетоксичные. Полученная модель должна иметь метрику качества F1 не ниже 0.75.

Задачи, решаемые в работе:
1. Подготовка данных для прогнозирования.
2. Обучение нескольких моделей и выбор лучшей.
3. Оценка качества работы модели.

План работы:
1. Загрузка данных и разбиение их на выборки.
2. Очистка и подготовка данных.
3. Получение эмбреддингов.
4. Формирование pipeline для обучения нескольких моделей.
5. Оценка качества лучшей модели.

Описание работы:
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

**Выводы по работе:**

В рамках работы сделано:
1. Загружены данные.
2. Датасет разделен на обучающий и отложенный.
3. Получены эмбреддинги с помощью модели Bert.
4. Обучены несколько моделей, такие как LogisticRegression, LGBMClassifier, CatBoostClassifier, XGBClassifier.
5. Выполнена оценка качества наилучшей модели.

Достигнутые результаты:
1. Наилучшей моделью стала LogisticRegression с метрикой F1 на обучеющем датасете 0.91.
2. Метрика F1 на отложенном датасете составила 0,91.
3. Чаще всего модель ошибается с категорией 1, ошибочно присваивая ей категорию 0 (нетоксично).

Рекомендации для улучшения прогноза:    
Предоставить дополнительную информацию о твитах, такую как дата твита, время, userid для распределения твитов по пользователям.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/wikishop.ipynb)


## Проект "Прогнозирование загруженности такси"

**Описание проекта**

Цель работы:
Разработать модель, способную предсказать количество заказов такси на следующий час.

Задачи, решаемые в работе:
1. Проанализировать предоставленные данные.
2. Подготовить данные для обучения.
3. Сформировать и обучить несколько моделей.
4. Сделать выводы о проведеннй работе.

План работы:
1. Загрузить данные.
2. Ресемплировать их по 1 часу.
3. Проанализировать данные.
4. Сформировать пайплайн для обучения моделей.
5. Обучить несколько моделей.
6. Выбрать лучшую из них.
7. Проанализировать работу лучшей из них на тестовой выборке.
8. Сформировать выводы.

Описание работы
Компания «Чётенькое такси» предоставила исторические данные о заказах такси в аэропортах. Задача компании - привлекать больше водителей на время высокого спроса. Для этих целей нужно моделей, которая предскажет часы с высоким спросом.
Предоставленные данные: таблица taxi.
Столбцы таблицы:
- datetime - содержит информацию о времени и дате.
- num_orders - содержит информацию о количестве заказов с интевалом в 10 минут.


**Выводы по работе:**
В рамках работы проведено:
1. Загрузка данных.
2. Ресемплирование значений.
3. Анализ предоставленной информации.
4. Обучение трех моделей: LGBMRegressor, CatBoostRegressor и LinearRegression.
5. Проведен контроль качества полученных моделей.

Результаты работы:
1. Наилучшая модель по результатам обучения оказалась LGBMRegressor.
2. Метрика модели составила 43.9, что меньше 48.

Рекомендации по улучшению качества прогноза:
1. Предоставить информацию о количестве заказов по районам города.
2. Предоставить информацию о классе машины для каждого заказа.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/taxi.ipynb)



## Проект "Прогнозирование вероятности ДТП в каршеринге"
**Описание проекта**

Цель работы: обучить и подобрать модель, способную предсказывать вероятность ДТП по историческим данным.

Задачи работы:

Провести анализ данных.
Сформировать как минимум 3 модели и обучить их.
Выбрать модель с наилучшими параметрами.
Определить наиболее важные факторы.
Предложить пути предотвращения ДТП.
План работы:

Получить данные из базы с помощью SQL-запросов.
Провести анализ данных.
Подготовить задания для коллег по изучению данных.
Сформировать и обучить как минимум три модели.
Выбрать наилучшую модель.
Проанализировать работу модели.
Сформировать выводы.
Описание работы: нужно создать систему, которая могла бы оценить риск ДТП по выбранному маршруту движения. Под риском понимается вероятность ДТП с любым повреждением транспортного средства. Как только водитель забронировал автомобиль, сел за руль и выбрал маршрут, система должна оценить уровень риска. Если уровень риска высок, водитель увидит предупреждение и рекомендации по маршруту. Идея создания такой системы находится в стадии предварительного обсуждения и проработки. Чёткого алгоритма работы и подобных решений на рынке ещё не существует. Текущая задача — понять, возможно ли предсказывать ДТП, опираясь на исторические данные одного из регионов.
Идея решения задачи от заказчика: Создать модель предсказания ДТП (целевое значение — at_fault (виновник) в таблице parties) Для модели выбрать тип виновника — только машина (car). Выбрать случаи, когда ДТП привело к любым повреждениям транспортного средства, кроме типа SCRATCH (царапина). Для моделирования ограничиться данными за 2012 год — они самые свежие. Обязательное условие — учесть фактор возраста автомобиля. На основе модели исследовать основные факторы ДТП. Понять, помогут ли результаты моделирования и анализ важности факторов ответить на вопросы: Возможно ли создать адекватную системы оценки водительского риска при выдаче авто? Какие ещё факторы нужно учесть? Нужно ли оборудовать автомобиль какими-либо датчиками или камерой?

Краткое описание таблиц

collisions — общая информация о ДТП. Эта таблица описывает общую информацию о ДТП. Например, где оно произошло и когда.
parties — информация об участниках ДТП.
vehicles — информация о пострадавших машинах.


**Выводы по работе:**
В рамках работы сделано:
1. Проведен исследовательский и корреляционный анализ данных.
2. Сформированы и обучены 4 модели.
3. Выбрана лучшая модель.
4. Определены факторы, наиболее влияющие на принятие решения.
5. Предложены пути снижения вероятности ДТП.

Результаты работы:
1. Наилучшая модель среди обученных - LGBMClassifier на основе градиентного бустинга. Метрика ROC-AUC на тестовой выборке составила 0,72.
2. Фактор, оказавший наибольшее влияние на решение модели - пил или нет человек алкоголь перед началом движения. Если он не пил, то чаще всего оказывался невиновным.

Рекомендации для улучшения прогноза:
1. Для улучшения прогноза желательно иметь больше информации о водителях, а именно возраст, стаж вождения, статистику по авариям.
2. Желательно также больше информации об автомобилях: марку, модель, пробег, информацию о последнем ТО и замене шин.

Общая резолюция:
по предоставленным данным трудно надежно спрогнозировать вероятность ДТП.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/predicting_the_probability_of_an_accident.ipynb)


## Проект "Прогнозирование температуры звезды"

**Описание проекта**
Цель работы:
Разработать нейронную сеть для прогнозирования температуры звезды.

Задачи работы:
1. Обработать предоставленные данные.
2. Разработать базовую модель.
3. Усовершенноствовать модель для достижения RMSE < 4500.

План работы:
1. Загрузка данных.
2. Обработка пропусков и дубликатов, если есть.
3. Исследовательский анализ данных.
4. Корреляционный анализ данных.
5. Подготовка данных для обучения (разделение, масштабирование)
6. Формирование базовой нейросети.
7. Усовершенствование нейросети.
8. Сведение полученных данных в общую таблицу.

Описание работы

Инициатор данной задачи - обсерватория «Небо на ладони». Необходимо с помощью нейросети определять температуру на поверхности обнаруженных звёзд. Обычно для расчёта пользуются методами:
- Закон смещения Вина.
- Закон Стефана-Больцмана.
- Спектральный анализ.

В базе обсерватории есть характеристики уже 240 звёзд.
Характеристики:
- Относительная светимость L/Lo — светимость звезды относительно Солнца.
- Относительный радиус R/Ro — радиус звезды относительно радиуса Солнца.
- Абсолютная звёздная величина Mv — физическая величина, характеризующая блеск звезды.
- Звёздный цвет (white, red, blue, yellow, yellow-orange и др.) — цвет звезды, который определяют на основе спектрального анализа.
- Тип звезды.
- Абсолютная температура T(K) — температура на поверхности звезды в Кельвинах.

**Выводы по работе:**
В рамках работы сделано:
1. Проведен исследовательский и корреляционный анализ.
2. Сформирована базовая нейросеть.
3. Улучшена базовая нейросеть.

Результаты работы:
1. В качестве базовой нейросети выбрана нейросеть из двух скрытых слоев. В первом слое 20 нейронов, во втором - 10. В качестве функций активации использовали LeakyReLU() и ReLU(). Метрика RMSE на этой модели после 5000 эпох обучения составила 6900.
2. Базовую нейросеть улучшили путем проведения обучения по batch и с применением Batch Normalization. Достигнутая метрика RMSE составила 3800, что меньше 4500.

Рекомендации для улучшения анализа:
1. Ввести более четкое описание цвета, возможно, с применением длины волны, для устранения двусмысленности.
2. Добавить большее количество наблюдений.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/predicting_the_temperature_of_a_star.ipynb)



## Проект "Определение стоимости автомобилей"
**Описание проекта**
Цель работы:  
Построить модель для определения стоимости автомобиля по набору признаков.

Задачи, решаемые в рамках работы:  
1. Предобработка данных (устранение пропусков, аномалий).
2. Исследовательский анализ данных.
3. Корреляционный анализ данных.
4. Построение моделей.
5. Анализ работы моделей.

План работы:  
1. Загрузить данные.
2. Устранить пропуски, аномалии.
3. Провести исследовательский анализ данных.
4. Рассчитать корреляции между признаками.
5. Построить модели и выбрать лучшую.
6. Проанализировать работу моделей.

Описание предоставленных данных:  
Предоставлен один датасет со следующими признаками:
- DateCrawled — дата скачивания анкеты из базы  
- VehicleType — тип автомобильного кузова
- RegistrationYear — год регистрации автомобиля
- Gearbox — тип коробки передач
- Power — мощность (л. с.)
- Model — модель автомобиля
- Kilometer — пробег (км)
- RegistrationMonth — месяц регистрации автомобиля
- FuelType — тип топлива
- Brand — марка автомобиля
- Repaired — была машина в ремонте или нет
- DateCreated — дата создания анкеты
- NumberOfPictures — количество фотографий автомобиля
- PostalCode — почтовый индекс владельца анкеты (пользователя)
- LastSeen — дата последней активности пользователя  
- Price — цена (евро) - целевой признак.

Оценка качества обучения модели:  
Качество обучения модели будет определяться по метрике RMSE. Она должна быть не более 2500.

**Выводы по работе:**
В рамках работы выполнено:
1. Подготовлены данные, удалены дубликаты, заполнены пропуски, устраненны аномалии.
2. Проведен исследовательский анализ данных.
3. Проведен корреляционный анализ данных.
4. Обучены две модели LGBMRegressor и LinearRegression.
5. Проанализирована скорость работы модели и их качество.

Результаты работы:
1. LGBMRegressor при обучении в Pipeline показал лучшие результаты, чем LinearRegression. Так, у LGBMRegressor RMSE составило около 1900, что соответствует требуемому значению.
2. RMSE для LinearRegression оказался значительно выше и составил около 3000. Значение не соответствует требованиям.
3. LGBMRegressor обучается медленне, чем LinearRegression, но дает лучшие результаты.
4. При прогнозе цены на автомобиль наибольшее значение имеют следующие признаки: год регистрации, мощность и факт ремонта автомобиля.

Предложения для улучшения качества модели:
1. Уточнить статус ремонта у машин, у которых он не был указан.
2. Добавить дополнительные признаки, к примеру, количество владельцев, состояние салона и кузова.


[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/determining_the_value_of_cars.ipynb)


## Проект "Предсказание стоимости жилья"
**Описание проекта**:
Цель работы: разработать две модели для предсказания медианной стоимости дома в жилом массиве. Первая модель со всеми данными, вторая - только с числовыми.

Задачи:
1. Обработать пропуски в данных.
2. Подготовить данные для моделей.
3. Обучить модели.
4. Оценить качество моделей по метрикам RMSE, MAE, R2.
5. Все работы проводить с помощью библиотеки Mlib в Spark.

План работы:
1. Загрузить данные.
2. Обработать пропуски.
3. Выполнить кодирование категориальных признаков.
4. Выполнить масштабирование числовых признаков.
5. Объединить обработанные данные.
6. Разделить данные на обучающую и тестовую выборки.
6. Обучить модели.
7. Получить получить предсказание моделей на тестовой выборке.
8. Рассчитать метрики RMSE, MAE, R2.
9. Сделать выводы по работе.

Описание предоставленных данных

В работе необходимо обучить модель линейной регрессии на данных о жилье в Калифорнии в 1990 году.
В колонках датасета содержатся следующие данные:
- longitude — долгота;
- latitude — ширина;
- housing_median_age — медианный возраст жителей жилого массива;
- total_rooms — общее количество комнат в домах жилого массива;
- total_bedrooms — общее количество спален в домах жилого массива;
- population — количество человек, которые проживают в жилом массиве;
- households — количество домовладений в жилом массиве;
- median_income — медианный доход жителей жилого массива;
- median_house_value — медианная стоимость дома в жилом массиве;
- ocean_proximity — близость к океану;
- rooms_per_household — отношение количества комнат total_rooms к количеству домовладений households (синтетический признак);
- population_in_household — отношение количества жителей population к количеству домовладений households (синтетический признак);
- bedroom_index — отношение количества спален total_bedrooms к общему количеству комнат total_rooms (синтетический признак).

**Выводы по работе:**
В рамках работы сделано следующее:

1. Обработаны пропуски в данных.
2. Подготовлены данные для моделей. Категориальные признаки закодированы, числовые признаки были масштабированы.
3. Обучены две модели: одна модель на полных данных, вторая модель на данных без категориальных признаков.
4. Работа моделей проанализирована по метрикам RMSE, MAE, R2.
Все работы проводили с помощью библиотеки Mlib в Spark. Необходимо отметить, что для обучения моделей использовались данные с синтетическими признаками: rooms_per_household, population_in_household, bedroom_index.

Результаты работы:  
Все три метрики у модели без категориального признака хуже, чем у модели, обученной на всех данных. Очевидно, учёт близости к океану играет важную роль в предсказании медианной стоимости дома в Калифорнии. Так, R2 у модели без категориального признака составляет 0,6, у модели на полных данных - 0,65.  

Рекомендации:  
Для улучшения точности предсказания рекомедуется добавить дополнительные признаки, к примеру:
- удаление от центра города;
- наличие объектов инфраструктуры;
- наличие метро, трамваем или другого общественного транспорта;
- другие особенности объектов недвижимости.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/predicting_the_value_of_housing.ipynb)


## Проект "Выбор локации для скважины"
**Описание проекта**
Цель работы:
Определить в каком из регионов прибыль от разработки нефтяных скважин будет наибольшая.

Задачи, направленные для достижения цели:
1. Построить модель и оценить её качество. Проанализировать модель.
2. На основании предоставленных данных и прогноза модели отобрать в каждом регионе 500 скважин для разработки.
3. Посчитать прибыль в каждом регионе и определить наиболее оптимальный.

План работы:

1. Загрузить данные.
2. Проверить данные на наличие пропусков и дубликатов.
3. Сформировать и обучить модель для прогноза запасов в каждой скважине.
4. Проверить качество работы модели по метрике RMSE.
5. Отобрать 500 скважин в каждом регионе с наибольшим запасом сырья.
6. Посчитать прибыль в каждом регионе методом Bootstrap, формируя выборки по 200 скважин.
7. Сделать выводы о наиболее оптимальном регионе для разработки.

Описание предоставленных данных
Предоставлено 3 таблицы с данными геологоразведки трёх регионов:
- geo_data_0.csv;
- geo_data_1.csv;
- geo_data_2.csv.
В каждой таблице присутствуют следующие столбцы:
- id — уникальный идентификатор скважины;
- f0, f1, f2 — три геологических признака скважины;
- product — объём запасов в скважине (тыс. баррелей).

Пояснение к работе
- При разведке региона исследуют 500 точек, из которых выбирают 200 лучших для разработки.
- Бюджет на разработку скважин в регионе — 10 млрд рублей.
- При нынешних ценах один баррель сырья приносит 450 рублей дохода. Доход с каждой единицы продукта в скважине составляет 450 тыс. рублей, поскольку объём указан в тысячах баррелей.
- После оценки рисков нужно оставить лишь те регионы, в которых вероятность убытков меньше 2.5%. Среди них выбирают регион с наибольшей средней прибылью.
- Данные синтетические: детали контрактов, характеристики месторождений, стоимости сырья и разработки не разглашаются.

**Выводы по работе**
В рамках работы выполнено:

1. Загружены и обработаны предоставленные данные.
2. Проведен анализ данных на наличие дубликатов, пропусков, аномальный и выпадающих значений.
3. Составлены и обучены ряд моделей для прогнозирования объёма сырья в скважине. 
4. Проанализированы признаки, на которых обучалась модель и установлены те, которые имеют наибольший вклад в конечный результат.
5. На основании результатов моделирования была посчитана ожидаемая прибыль в каждом регионе и вероятность возникновения убытков.

Основные результаты работы:
1. На основании предоставленных данных установлено, что в регионе 1 наибольший средний объём на скважину. Следовательно, в этом регионе ожидаемая прибыль также наибольшая. Ожидаемая прибыль составляет 35.73 - 828.01 млн. рублей на весь регион. Указанный регион рекомендуется для разработки.
2. На результат прогноза модели наибольшее влияние оказывает показатель f2. 
3. Только в регионе 1 вероятность убытков ниже 2,5%, в других регионах она значительно выше.


Рекомендации для улучшение качество прогноза:

1. Предоставить данные по другим регионам для уточнения модели.
2. По возможности предоставить другие показатели к скважинам. Возможно, есть какие-то признаки, которые позволят уточнить расчет.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/selecting_a_location_for_a_well.ipynb)


## Проект "Оценка уровня удовлетворенности сотрудников"
**Описание проекта**
Цель работы:
1. Оценить уровень удовлетворенности каждого сотрудника.
2. Оценить вероятность увольнения каждого сотрудника.

Задачи, направленные для достижения цели:
1. Проанализировать предоставленные данные на наличие выбросов, пропусков, аномальных значений.
2. Провести исследовательских и корреляционный анализ данных.
3. Сформировать признаки для обучения моделей.
4. Сформировать и обучить две модели: первая модель для предсказания уровня удовлетворенности, вторая модель - для предсказания вероятности увольнения сотрудника.

План работы:
1. Загрузить данные.
2. Проверить данные на наличие пропусков, выбросов и аномальных значений.
3. Провести исследовательский анализ данных.
4. Провести корреляционный анализ данных.
5. Сформировать и обучить модель для прогноза уровня удовлетворенности.
6. Проверить качество работы модели на тестовых данных.
7. Сформировать и обучить модель для прогноза вероятности увольнения сотрудника.
8. Проверить качество работы модели на тестовых данных.
9. Подвести итоги и сформировать выводы.

Оценка качества моделей  
Для оценки качества модели прогнозирования уровня удовлетворенности будет использоваться метрика SMAPE, рассчитываемая из следующих показателей:
- фактическое значение уровня удовлетворенности для объекта из выборки;
- предсказанное значение уровня удовлетворенности для объекта из выборки;
- количество объектов в выборке.
Критерием успеха модели является SMAPE ≤15 на тестовой выборке.

Модель прогнозирования вероятности увольнения будет оцениваться по метрике ROC-AUC.
Критерий успеха: ROC-AUC ≥ 0.91.

Пояснение к работе  
HR-аналитики компании «Работа с заботой» помогают бизнесу оптимизировать управление персоналом: бизнес предоставляет данные, а аналитики предлагают, как избежать финансовых потерь и оттока сотрудников. 
Для этих целей HR-аналитикам необходимы модели, с помощью которых они смогут прогнозировать уровни удовлетворенности сотрудников, а также вероятность их увольнения.
Уровень удовлетворенности, представленный в тестовых таблицах, получен в результате опроса сотрудников и рассчитан в диапазоне от 0 до 1, где 0 — совершенно неудовлетворён, 1 — полностью удовлетворён.
Прогнозировать уровень удовлетворенности и вероятность увольнения сотрудника крайне важно для компании, так как в случае увольнения важного сотрудника возрастает риск возникновения серъезных убытков. 

**Вывод по работе:**
В рамках работы выполнено:
1. Загружены и обработаны предоставленные данные. 
2. Проведен исследовательский анализ данных на наличие аномальный и выпадающих значений.
3. Проведен корреляционный анализ данных.
4. Составлены и обучены ряд моделей для прогнозирования уровня удовлетворенности сотрудников и вероятности их увольнения.
 
 
Основные результаты работы:
1. В представленных данных не было пропусков, но были значения, значительно отклоняющиеся от средних.
2. Во время исследовательского анализа данных установлено следующее:
- Люди, которые работают на позиции junior, в большинстве своём работают недолго, до 4 лет.
- Чаще всего компанию покидают те, кто работает 1 год.
- В целом компанию чаще покидают те, кто имеет оценку 3 и ниже от руководителя.
- Чаще всего компанию покидают те, у кого прогнозируется низкая удовлетворенность.
- Особенности уровня удовлетворенности отмечаются только на диаграммах о последнем повышении и о нарушение трудового договора. Так, тех, у кого за последний год повысили, уровень удовлетворенности высокий, а те, которые были замечены за нарушением трудового договора уровень удовлетворенности низкий.
- 28% сотрудников готовы покинуть компанию.
3. При корреляционном анализы выявлено следующее:
- Удовлетворенность сотрудника относительно сильно коррелирует с оценков от руководителя supervisor_evaluation и с наличием нарушений договора за последний год.
- Вероятность увольнения сотрудника значительно коррелирует с предсказанным уровнем удовлетворенности, с зарплатой и с количеством отработанных лет.
- Вероятность ухода сотрудника из компании не коррелирует с отделом, где он работает.
3. Среди разработанных и испытанных моделей наилучшие:
- для прогнозирования уровня удовлетворенности DecisionTreeRegressor с параметрами max_depth=19, max_features=12, min_samples_leaf=3, min_weight_fraction_leaf=0.
- для прогнозирования вероятности увольнения DecisionTreeClassifier со следующими параметрами: max_depth=5, max_features=5.


Рекомендации для увеличения удовлетворенности сотрудников:
1. Разработать систему мотивации с поощрением в виде небольших повышений.
2. Рассмотреть возможность предотвращения нарушений трудового договора без необходимости дисциплинарного взыскания.

Рекомендации для уменьшения вероятности увольнения сотрудников:
1. Не допускать снижение уровня удовлетворенности сотрудника.
2. Для сотрудников, у которых высока вероятность увольнения, рассмотреть возможность поощрений.

Рекомендации для повышения качества анализа и прогнозирования:  
Представить данные за другие отделы или периоды опробирования моделей на новых данных. 

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/assessment_of_employee_satisfaction_levels.ipynb)


## Проект "Персонализация предложений для пользователей"
**Описание проекта**
Цель работы  
Разработать решение, которое позволит персонализировать предложения постоянным клиентам.

Ожидаемый эффект от реализации проекта  
Увеличение покупательской активности постоянных клиентов.

Задачи, направленные на достижение цели
1. Промаркировать уровень финансовой активности постоянных покупателей ("снизилась", "прежний уровень").

2. Сгруппировать данные по клиентам по следующим группам: 
- Признаки, которые описывают коммуникацию сотрудников компании с клиентом.
- Признаки, которые описывают продуктовое поведение покупателя. Например, какие товары покупает и как часто.
- Признаки, которые описывают покупательское поведение клиента. Например, сколько тратил в магазине.
- Признаки, которые описывают поведение покупателя на сайте. Например, как много страниц просматривает и сколько времени проводит на сайте.
3. Дополнить информацию дополнительными данными финансового департамента о прибыльности клиента: какой доход каждый покупатель приносил компании за последние три месяца.
4. Построить модель, которая предскажет вероятность снижения покупательской активности клиента в следующие три месяца.
5. На основе собранных данных и данных модели выделить сегменты покупателей и разработать для них персонализированные предложения.

План работы  
1. Загрузить данные, оценить количество пропусков, наличие дубликатов.
2. Провести исследовательский анализ данных на наличие аномальных, выпадающих значений.
3. Провести корреляционный анализ данных.
4. Составить, обучить и оценить различные модели для предсказания целевых признаков.
5. Сегментировать покупателей на основе полученных данных.

**Выводы по работе:**
В рамках работы выполнено:
1. Загружены и обработаны предоставленные данные. 
2. Проведен исследовательский анализ данных на наличие аномальный и выпадающих значений.
3. Проведен корреляционный анализ данных.
4. Составлены и обучены ряд моделей для прогнозирования покупательской активности. Среди моделей выбрана модель с наиболее точными результатами. Использованные в работе модели: метод опорных векторов, миетод k-ближайших соседей, дерево решений и логистическай регрессия.  
5. Проанализированы признаки, на которых обучалась модель и установлены те, которые имеют наибольший вклад в конечный результат.
6. На основании результатов моделирования были выделены сегменты покупателей и выданы рекомендации по увеличению покупательской активности. В рамках работы был подробно рассмотрены покупатели, приносящие наибольшую прибыль, но покупательская активность которых снижается.
 
Основные результаты работы:
1. В представленных данных не было пропусков, но были значения, значительно отклоняющиеся от средних.
2. При корреляционном анализе было выявленно, что выручка предыдущего месяца сильно коррелирует с выручкой текущего месяца (линейная зависимость). В связи с этим при моделировании зависимость была устранена путем возведения значений выручки текущего месяца в квадрат.
3. Среди разработанных и испытанных моделей наилучший результат показала модель на основе метода опорных векторов с методом масштабирования StandartScale. Модель позволяет предсказывать снижение или сохранение покупательской активности конкретного пользователя на основе ряда признаков.
4. Анализ результата работы модели выявил, что наибольшее влияние при прогнозировании оказывает время, проведенное на сайте, в текущем и предыдущем месяце, а также среднее количество просмотренных категорий товаров за квартал.
5. Касательно рассмотренного сегмента пользователей. Пользователи из этой категории в среднем получали меньше маркетинговой информации, меньше проводили время на сайте и просматривали меньше страниц. При этом имеют сравнительно высокое количество неоплаченных товаров в корзине. Наиболее популярная категория - товары для детей.

Рекомендации для увеличения покупательской активности выделенного сегмента пользователей:
1. Увеличить количество маркетинговых коммуникаций. Предположительно, это также приведет к увеличению времени нахождения на сайте и к увеличению количества просмотренных страниц.
2. Рассмотреть возможность проведения акций для товаров, находящихся в корзине у пользователей рассматриваемого сегмента. Данные анализа показывают, что пользователи из этого сегмента охотно откликаются на акции.

Рекомендации для повышения качества анализа и прогнозирования:  
Представить данные за другие периоды для опробирования модели на новых данных.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/personalization_of_offers_for_users.ipynb)


## Проект "Отбор буренок для покупки"
**Описание проекта**
Заказчик: Молочное хозяйство «Вольный луг».  
Дата проведения анализа: Март-апрель 2024 года.  
Цель, сформированная заказчиком: Отобрать из коров, предлагаемых к покупке ассоциацией пастбищ «ЭкоФерма», только тех, которые отвечают следующим критериям:
1. Каждая из отобранных коров должна давать не менее 6000 килограммов молока в год.
2. Молоко должно соответствовать по вкусовым качества, предъявляемых молочным хозяйством «Вольный луг».


Задачи, направленные на достижение цели:
1. Разработать модель, прогнозирующую возможный удой каждой коровы.
2. Разработать модель, прогнозирующую вероятность получить вкусное молоко от коровы.

План работы
1. Загрузить и оценить данные.
2. Предварительно обработать данные: устранить дубликаты, заполнить по возможности пропуски.
3. Исследовать данные: выделить аномальные значения и принять решение о включении их в анализ. Выявить зависимости и распределения.
4. Корреляционный анализ: выявить зависимости среди данных.
5. Обучить модель линейной регрессии и проанализировать её результаты.
6. Обучить модель логистической регрессии и проанализировать её результаты.
7. Сформулировать выводы и рекомендации.

Особенности:
- Содержание белков и жиров в молоке указано на момент продажи.
- Ассоциация «ЭкоФерма» давала коровам свой корм.
- Отсутствуют параметры корма ЭКЕ (Энергетическая кормовая единица), Сырой протеин, г и СПО (Сахаро-протеиновое соотношение). 
- Технологи заказчика пересмотрели подход к кормлению: для новых коров планируется увеличить значения каждого параметра корма на 5%.

В представленных данных отсутствуют целевые признаки: 
- Удой.
- Качество (вкус) молока.

**Выводы по работе:**
В рамках работы выполнено следующее:
1. Обработаны изначальные данные, удалены дубликаты и аномальные значения.
2. Обучены 3 модели линейной регрессии и 1 модель логистической регрессии.
3. Определены показатели точности данных моделей.  

Для улучшения качества моделей были использованы следующие методы:
- ввод дополнительный параметров (тип СПО, ЭКЕ в квадрате),
- добавлены сведения об отце коровы,
- установлен определенный порог классификации для модели логистической регрессии. 

Для оценки качества модели классификации использовалась метрика Presicion.  
4. На основании моделей спрогнозирована величина удоя и вкус молока для коров, планируемых к покупке.

На основании полученных прогнозов рекомендуется к покупке только 2 коровы из представленного списка. 

Выявились следующие закономерности:
- Удой зависит от возраста коровы. В среднем удой больше, чем больше возраст коровы.
- Удой зависит от Энергетической кормовой единицы. Чем выше ЭКЕ, тем выше удой, но зависимость нелинейная.
- Удой зависит от Сахаро-протеинового соотношения. При соотношении выше 0,92 удой резко увеличивается.
- Среди коров с самым высоким удоем большинство коров, чей отец был породы Айдиал.
- Коровы, которые имеют наибольший удой, имеют и также вкусное молоко.

Рекомендации для фермера:
- Высокий удой можно достичь, если следить за питанием коров и держать ЭКЕ и СПО на высоком уровне. 
- При планировании производства необходимо учитывать, что только коровы старше 2 лет дают высокий удой. При этом не гарантируется, что после двух лет корова будет давать удой свыше 6000 кг, хотя это весьма вероятно.
- Рекомендуется обращать внимание на породу отца коровы. Вероятность высокого удоя увеличивается, если отец коровы был породы Айдиал. Среди коров, чей отец был породы Соверинг, высокий удой встречается значительно реже.
- Не принципиально, на каком пастбище пасти коров. Величина удоя от этой практически не зависит.

Для увеличения точности прогноза рекомендуется:
- Предоставить величины ЭКЕ и СПО для коров, планируемых к приобретению.
- Расширить классификацию по возрасту коровы: вместо старше/младше 2 лет желательно указывать конкретный возраст каждой коровы.
- Предоставить информацию о матери коровы, её породе и качестве её молока.
- Возможно на качество молока влияет наличие или отсутствие телят у каждой коровы. Рекомендуется предоставить информацию по ним.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/selection_of_cows_for_purchase.ipynb)

## Проект "Анализ сервиса проката самокатов"
**Описание проекта**
GoFast - сервис аренды самокатов, работающий в нескольких городах России. Для совершения поездки пользователь арендует самокат через собственное мобильное приложение сервиса. Возможны два варианта аренды: с подпиской Ultra и без подписки. Подробные условия приведены в таблице: 

|Условия|Без подписки|С подпиской Ultra|
|-|--------|---|
|Абонентская плата|отсутствует|199 рублей|
|Стоимость одной минуты поездки|8 рублей|6 рублей|
|Стоимость старта|50 рублей|бесплатно|



Цели анализа 
1. Установить, кто пользуется сервисом. 
2. Установить, какие факторы влияют на выручку сервиса.  

Результаты работы могут быть использованы для повышение рентабельности бизнеса.

Задачи, решаемые в ходе анализа
1. Предварительная обработка данных.  
Под обработкой подразумевается:
- приведение типа данных к нужному типу,
- обработка пропусков,
- обработка дубликатов.
2. Выполнение визуализации данных:
- распределение пользователей по городам,
- соотношение пользователей с подпиской и без неё,
- распределение пользователей по возрасту,
- распределение продолжительности поездок,
- распределение дистанции поездок.
3. Подсчет помесячной выручки от пользователей с подпиской и без подписки.
4. Проверка гипотез касательно сервиса:
- тратят ли пользователи с подпиской больше времени на поездки,
- среднее расстояние, которое проезжают пользователи с подпиской за одну поездку, не превышает 3130 метров,
- помесячная выручка от пользователей с подпиской по месяцам выше, чем выручка от пользователей без подписки.

Описание начальных данных   
Для анализа предоставлены три таблицы с данными.
1. Таблица с информацией о пользователях (файл "users_go.csv").

|Столбец|Описание|
|-|--------|
|user_id|уникальный идентификатор пользователя|
|name|имя пользователя|
|age|возраст|
|subscription_type|тип подписки (free, ultra)|

2. Таблица с информацией о поездках (файл "rides_go.csv").

|Столбец|Описание|
|-|--------|
|user_id|уникальный идентификатор пользователя|
|distance|расстояние, которое проехали в текущей сессии (в метрах)|
|duration|продолжительность сессии (в минутах)|
|date|дата совершения поездки|


3. Таблица с информацией о подписках (файл "subscriptions_go.csv").

|Столбец|Описание|
|-|--------|
|subscription_type|тип подписки|
|minute_price|стоимость одной минуты поездки|
|start_ride_price|стоимость начала поездки|
|subscription_fee|стоимость ежемесячного платежа|

План работы
1. Загрузка данных.
2. Предварительная обработка.  
3. Выполнение визуализации в соответствии с задачами.
4. Подсчет помесячной выручки от пользователей с подпиской и без подписки.
5. Проверка ряда гипотез.

**Выводы по работе:**
Обработка данных  
В рамках работы были обработаны данные из трех файлов: 
- сведения о пользователях, 
- сведения о поездках, 
- сведения о подписках.  

В начальных данных пропусков не было обнаружено. Вместе с тем, в файле о поездках были найдены аномальные значения. Так, в файле было 95 строк, в которых расстояние поездки составляло более 4 километров, но время поездки было всего 0,5 минуты.

Анализ данных и проверка гипотез.  
Были построены визуализации и определено следующее:
- больше всего пользователей сервиса из Пятигорска. Всего сервис представлен в 8 городах.
- среди пользователей сервиса большинство не пользуется подпиской (54%).
- сервисом пользуются люди от 12 до 43 лет.
- средняя дистанция, на которую совершают поездки, около 3 километров. При этом средняя скорость движения составляет 10 км/ч.  

Сформулированы и проверены следующие гипотезы:
- пользователи с подпиской тратят больше времени на поездки. Вывод: скорее всего, так и есть. Проверка гипотезы были осуществлена с помощью двухвыборочного t-теста для независимых выборок.
- пользователи с подпиской ездят меньшее, чем 3130 метров за одну поездку. Вывод: не удалось опровергнуть. Скорее всего, так и есть. Проверка гипотезы была осуществлена одновыборочным t-тестом.
- пользователи с подпиской приносят больше выручки, чем пользователи без подписки. Вывод: не удалось опровергнуть. Вероятно, пользователи с подпиской приносят больше выручки. Проверка гипотезы была осуществлена с помощью двухвыборочного t-теста для независимых выборок.  

Решены задачи: 
- установлено необходимое количество промокодов: минимум 1173 промокода.
- установлена вероятность, что уведомления откроют менее 399 500 раз: 15,4%.

Рекомендации по улучшению и уточнению анализа  
В целях уточнения результатов анализа рекомендуется:
- предоставить данные за другие временные промежутки.
- предоставить данные после модернизации приложения сервиса. О модернизации приложения говорилось в п. 7.4.
- проверить алгоритм сбора и выгрузки данных на возможные ошибки. Указанные выше 95 строк с аномально большим расстоянием при аномально малом времени возможно связаны с ошибкой в алгоритмах сбора и выгрузки данных.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/analysis_of_the_scooter_rental_service.ipynb)


## Проект "Исследование данных о российском кинопрокате"
**Описание проекта**
Цель исследования: изучения рынка российского кинопроката и выявление текущих трендов.

Задачи исследования:
1. Предварительно обработать данные для устранения пропусков, аномалий и других дефектов, если это возможно и целесообразно.
2. Определить, сколько фильмов выходило каждый год и как менялась динамика проката по годам.
3. Определить, как влияет государственная поддержка на финансовые результаты фильмов и оценку зрителей.

Объект исследования: открытые данные Министерства культуры Российской Федерации и сайта КиноПоиск о прокатных удостоверениях, сборах и государственной поддержке фильмов.

**Выводы по работе:**
Предварительная обработка данных.
1. В представленных данных имеются лишние символы, опечатки и дубликаты. Так, имеются задвоенные номера прокатных удостоверений, неверное написание фильмов, разные варианты написания имени режиссеров и т.д.
2. В предоставленной информации имеются пропуски в некоторых столбцах, среди которых столбцы с бюджетом фильма, с доходами от проката и объемами государственного финансирования.
3. В рамках предварительной подготовки были удалены или откорректированы некорректные значения в столбцах с рейтингом, бюджетом, доходом от проката. Кроме того, были изменены типы данных там, где это было необходимо.
4. Добавлены новые столбцы на основе представленной информации. Среди этих столбцов: имя главного режиссера, год выхода фильма, доля государственного финансирования в общем бюджете фильма.

Анализ представленной информации.  
По результатам исследования установлено:  
1. Доля фильмов, показанных в кинотеатрах, с 2010 года растет.
2. Максимальный доход от проката был в 2018 году, после чего он снизился.
3. Наибольший доход до 2019 года приносили фильмы категории 16+, но в 2019 году доход от фильмов категорий 12+ и 16+ практически сравнялся. Вместе с тем постоянно растет доход фильмов с категорией 18+, но до уровня категорий 12+ и 16+ ещё не доходит.
4. Государственное финансирование не влияет на рейтинг фильма, так как не наблюдается зависимость между объемом финансирования и оценками фильма после выхода.
5. Чаще всего государственные структуры поддерживают фильмы в жанре драма. При этом фильмы категории 12+ получают большее финансирование.

Мероприятия для повышения качества анализа.  
В целях улучшения качества анализа желательно:
1. Дополнить данные информацией по общим бюджетам фильмов, величине финансирования и доходам от проката.
2. Откорректировать сбор данных для предотвращения записи дубликатов и ошибок в названиях фильмов, именах режиссеров и т.д.
3. Предоставить информацию за более поздний период (после 2020 года).

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/research_of_russian_film_distribution.ipynb)

## Проект "Исследование объявлений о продаже квартир"
**Описание проекта**
В вашем распоряжении данные сервиса Яндекс Недвижимость — архив объявлений о продаже квартир в Санкт-Петербурге и соседних населённых пунктах за несколько лет. Вам нужно научиться определять рыночную стоимость объектов недвижимости. Для этого проведите исследовательский анализ данных и установите параметры, влияющие на цену объектов. Это позволит построить автоматизированную систему: она отследит аномалии и мошенническую деятельность.

По каждой квартире на продажу доступны два вида данных. Первые вписаны пользователем, вторые — получены автоматически на основе картографических данных. Например, расстояние до центра, аэропорта и других объектов — эти данные автоматически получены из геосервисов. Количество парков и водоёмов также заполняется без участия пользователя.

**Выводы по работе**

1. Предварительная обработка данных
- В представленных данных были пропущены значения, среди которых площади (жилая, кухонная) квартиры, расстояние до парков и озер, наличие или отсутствие балконов. Причина отсутствия значений: пользователи не указали данные величины при заполнении объявления, так как либо этих параметров нет, либо пользователи не знали нужные значения.
- В ряде данных, к примеру, в высоте потолков, были допущены ошибки. Так, встречались значения 14 метров, 30 метров, 100 метров. Причина таких значений: ошибка пользователя при заполнении объявления. Указанные величины были удалены из выборки либо скорректированы.
- В присланных значениях были по разному указаны названия городов и населенных пунктов. Для корректного расчета названия городов и населенных пунктов были приведены к одному значению.
- В целях упрощения анализа были добавлены новые столбцы: стоимость одного квадратного метра, день, месяц и год подачи объявления, переведено расстояние до центра города из метров в километры.

2. Основные выводы исследования
- Большинство объявлений актуальны на сайте на срок до 100 дней, однако есть объявления, которые "висят" свыше 1500 дней.
- Сильнее всего на стоимость квартиры влияют площади квартиры (общая, жилая, кухни) и количество комнат. В тоже время стоимость квартиры не зависит от месяца подачи объявления. Следовательно, сезонность на стоимость квартиры практически не вляет. Однако отмечается зависимость: дороже квартиры, объявления о которых размещены во вторник.
- Наибольшая цена за квадратный метр наблюдается в Санкт-Петербурге, наименьшая - в Выборге (из наиболее крупных городов).
- В Санкт-Петербурге цена квартиры снижается по мере удаления от центра: чем дальше от центра, тем дешевле квартира.

3. Рекомендации  
В целях улучшения качества анализа рекомендуется выполнить следующее:
- Предоставить данные за больший временной период.
- Организовать базу населенных пунктов и ограничить возможные варианты в столбце "locality_name" только значениями данной базы. Это позволит точнее соотносить населенные пункты.
- Предоставить данные по ориентировочному адресу объектов. Это позволит устранить пропуски в столбцах расстояния до парков, аэропортов, прудов.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/advertisements_for_sale_of_apartments.ipynb)

## Проект "Исследование надежности заемщиков"
**Описание проекта**
Заказчик — кредитный отдел банка. Нужно разобраться, влияет ли семейное положение и количество детей клиента на факт погашения кредита в срок. Входные данные от банка — статистика о платёжеспособности клиентов.
Результаты исследования будут учтены при построении модели кредитного скоринга — специальной системы, которая оценивает способность потенциального заёмщика вернуть кредит банку.

**Выводы по работе**
1. Представлены исходные данные в количестве 21525 строк. В 2174 строке были обнаружены пропущенные значения. Пропущенные значения были в стоблцах "days_employed" (количество дней занятости) и в "total_income" (общий доход). Пустые значения были заменены на медианные в целях повышения точности анализа.  
Также были обнаружены аномальные значения в столбце "children" (дети): 20 и -1. Указанные значения были удалены как аномальные.  
Для удобства анализа общие доходы и цели кредитов были разделены на категории.
2. В общем случае на вероятность возникновения просрочки по кредиту влияет:
- семейное положение человека. Так, среди вдовцов/вдов наблюдается наименьшая доля просрочек.
- цель кредита. Наименьшая доля просрочек у кредитов, выданных для операций с недвижимостью.
- наличие или отсутствует детей. У людей с детьми доля просрочек больше, чем у людей без детей.  
- На основе представленных данных нет возможности сделать вывод о связи между доходом человека и вероятностью возникновения задолжности.
3. В целях уточнения анализа предлагается:
- дополнить данные по доходам из других источников, к примеру, по данным различных фондов социальной поддержки.
- собрать данные по величине задержек по кредитам у людей с высоким доходом и с низким доходом. Возможно, указанные данные могут сделать выводы о зависимости доходов и вероятности просрочки по кредиту. 

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/research_of_borrower_reliability.ipynb)


## Проект "Прогнозирование успешности стартапа"
**Описание проекта**
Цель работы: предсказать закроется тот или иной стартап.  

Задачи:
1. Подготовить данные: заполнить пропуски, ввести новые категории, по возможности убрать аномальные значения.
2. Составить pipeline и подобрать наилучшую модель.
3. Получить предсказание модели на тестовой выборке.

План работы:
1. Загрузить данные.
2. Оценить количество пропусков и по возможности устранить их.
3. Оценить количество дубликатов и по возможности устранить их.
4. Оценить распределение данных и по возможности устранить аномальные значения.
5. Ввести новые признаки на основе имеющихся.
6. Составить матрицу корреляции признаков.
7. Составить pipeline с несколькими моделями.
8. Подобрать в pipeline оптимальную модель и рассчитать её качество.
9. Получить предсказание лучшей модели на тестовых значениях.

**Выводы по работе:**
В рамках работы выполнено следующее:
1. Заполнены пропуски в данных.
2. Рассчитаны новые признаки.
3. Обучена модель и получено предсказания для тестовой выборки. Для лучшей модели на тренеровочном набор f1-мера составила 0,96. В тестовом датасете для 915 компаний прогнозируется закрытие.
4. Установлено, что наибольший вклад в модель вносит признак с количеством раундов финансирования.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/predicting_startup_success.ipynb)

### Проект "Категоризация клиентов маркетплейса"
**Описание проекта:**
Цель работы: разработать модель для распределения клиентом на условные категории 1 и 0, где 1 - совершит покупки в течение следующих 90 дней, 0 - не совершит.

Задачи, решаемые в рамках работы:
1. На основе предоставленных данных сформировать признаки, которые позволят распределить клиентов на категории.
2. Обработать собранные признаки для удаления аномалий, выбросов, пустых значений.
3. Подготовить данные для обучения (закодировать признаки и выполнить масштабирование).
4. Подобрать и обучить модель бинарной классификации.
5. Проверить качество модели по метрике ROC-AUC.
6. Проанализировать работу модели.

План работы:
1. Загрузить данные и ознакомиться с ними.
2. Сформировать новые признаки в исходные таблицы.
3. Сгруппировать из исходных данных признаки для категоризации клиентов.
4. Обработать аномальные и выпадающие значения в собранных признаках.
5. Разделить данные на выборки.
6. Подготовить данные для обучения.
7. Сформировать Pipeline с несколькими моделями для нахождения оптимальной.
8. Выгрузить из Pipeline лучшую модель и оценить её качество на валидационной выборке.
9. Проанализировать работу модели, определив, какие признаками вносят наибольший вклад.
10. Сделать выводы по работе.

Описание работы, предоставленное заказчиком:
Интернет-магазин собирает историю покупателей, проводит рассылки предложений и планирует будущие продажи. Результаты работы будут использованы для оптимизации процессов.

**Выводы по работе:**
В работе выполнено следующее:
1. Создано около 23 признаков для передачи в модель.
2. Проведен исследовательский и корреляционный анализ данных.
3. Сформирован Pipeline и выбрана наилучшая модель.
4. Проверена работа модели на данных, которые ранее ей не были показаны.
5. Проведен анализ работы модели, установлен вклад каждого признака в модель.

Результаты работы:
1. Наилучшая модель оказалась LogisticRegression с методом подготовки данных
2. Достигнуто значение метрики ROC-AUC 0,701 на тренировочных данных и 0,704 на валидационных.
3. Наибольший вклад в работу модели вносит количество заказов в 2024 году.

Предложения по улучшению прогноза:
1. Предоставить дополнительные признаки по клиентам, к примеру, пол, возраст.
2. Оптимизировать сбор информации по категориям товаров.

[Посмотреть работу можно тут](https://github.com/YakovlevIvanG/learning/blob/main/categorization_of_marketplace_clients.ipynb)
